# RL-Adventure
Reinforcement Learning Adventure

## Intro

In this little project, I aim at summarizing the Reinforcement Learning knowledge, step by step. The motivation is to organize what I have learned from Udacity Deep Reinforcement Learning Nanodegree and goes beyond. Here I will write blogs and codes for the basic knowledges and also for the important papers in this area, starting with the recommandation in the Nanodegree.

The main 'Adventure' play ground will be in OpenAI's gym environment.

## Refences
**Notice** that many of my codes will be referencing the Nanodegree contents and other excellent implementations on Github.

- [Udacity DRLND course](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893)

- ['SuttonBartoIPRLBook2ndEd'](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)

- [UCL Deep Reinforcement Learning course](http://rail.eecs.berkeley.edu/deeprlcourse/)

- the excellent algorithm implementations like [ShangtongZhang](https://github.com/ShangtongZhang/DeepRL) and [rlcode](https://github.com/rlcode/reinforcement-learning) on Github.

- [Pinard's blog (in Chinese)](https://www.cnblogs.com/pinard/category/1254674.html)

- [Andrej Karpathy blog](karpathy.github.io/2016/05/31/rl/)

- [icml deep_rl_tutorial](https://icml.cc/2016/tutorials/deep_rl_tutorial.pdf)



## Recent Plan and Progress (up to 2019-05-19)

- Blogs writing (20% completed)
- [Reinforcement Learning Intro](https://github.com/quboanthony/RL-Adventure/blob/master/RL_learning/RL_Learning_blog_1.md) (blogs 30% completed)
- Dynamic Progrmming (0% completed)
- Classic
  - [Monte Carlo method](https://github.com/quboanthony/RL-Adventure/tree/master/monte-carlo) (workable codes implemented, Blogs 0% completed)
  - [Temporal-Difference methods](https://github.com/quboanthony/RL-Adventure/tree/master/temporal-difference) (workable codes implemented, Blogs 0% completed)
  - RL in Continous Space (Blogs 0% completed)
- Value-based methods
  - [Classic DQN with image inputs for learning](https://github.com/quboanthony/RL-Adventure/tree/master/p1_navigation_learning_from_pixels)(workable codes implemented, still tuning for request performance...)
  - [Classic DQN](https://github.com/quboanthony/RL-Adventure/tree/master/p1_navigation) (workable codes implemented, blogs 0% completed)
  - [Double-DQN](https://github.com/quboanthony/RL-Adventure/tree/master/dqn-double_dqn
) (workable codes implemented, blogs 0% completed)
  - [Prioritized Replay DDQN](https://github.com/quboanthony/RL-Adventure/tree/master/dqn-Prioritized%20Experience%20Replay%20ddqn) (workable codes implemented, blogs completed)
  - [Dueling-DQN](https://github.com/quboanthony/RL-Adventure/tree/master/dqn-duelingdqn) (workable codes implemented, blogs completed)
- Policy-based methods
  - [Policy-based and Hill climbing algorthm](https://github.com/quboanthony/RL-Adventure/blob/master/RL_learning/RL_Learning_blog_11.mds)(blogs and workable codes completed)
  -[Policy Gradients method](https://github.com/quboanthony/RL-Adventure/blob/master/RL_learning/RL_Learning_blog_12.mds)(Blogs completed)

  -[Proximal  Policy Optimization]()(working on blogs)
